{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-format conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!docling --version\n",
    "!pip install pyarrow\n",
    "!pip install -qU docling transformers\n",
    "!pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv\n",
    "!pip install milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting pdf to md, json, and yaml formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    ")\n",
    "from docling_core.types.doc import PictureItem\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import FigureElement, InputFormat, Table\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "import pandas as pd\n",
    "import time\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    EasyOcrOptions,\n",
    "    OcrMacOptions,\n",
    "    PdfPipelineOptions,\n",
    "    RapidOcrOptions,\n",
    "    TesseractCliOcrOptions,\n",
    "    TesseractOcrOptions,\n",
    "    AcceleratorDevice,\n",
    "    AcceleratorOptions,\n",
    "    granite_picture_description,\n",
    "    smolvlm_picture_description,\n",
    ")\n",
    "from docling.datamodel.settings import settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_paths = [\n",
    "        # Path(\"inputs/Improving_machine-learning_models.pdf\"),\n",
    "        Path(\"inputs/Finite_Element_Modeling_Shape_Changes_Plant_Cells.pdf\"),\n",
    "    ]\n",
    "\n",
    "    ## for defaults use:\n",
    "    # doc_converter = DocumentConverter()\n",
    "\n",
    "    ## to customize use:\n",
    "    doc_converter = (\n",
    "        DocumentConverter(  # all of the below is optional, has internal defaults.\n",
    "            allowed_formats=[\n",
    "                InputFormat.PDF,\n",
    "                InputFormat.IMAGE,\n",
    "                InputFormat.DOCX,\n",
    "                InputFormat.HTML,\n",
    "                InputFormat.PPTX,\n",
    "                InputFormat.ASCIIDOC,\n",
    "                InputFormat.MD,\n",
    "            ],  # whitelist formats, non-matching files are ignored.\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_cls=StandardPdfPipeline, backend=PyPdfiumDocumentBackend\n",
    "                ),\n",
    "                InputFormat.DOCX: WordFormatOption(\n",
    "                    pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    conv_results = doc_converter.convert_all(input_paths)\n",
    "\n",
    "    for res in conv_results:\n",
    "        # Create an output directory for each input file\n",
    "        out_dir = Path(\"outputs\") / res.input.file.stem\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(\n",
    "            f\"Document {res.input.file.name} converted.\"\n",
    "            f\"\\nSaved markdown output to: {str(out_dir)}\"\n",
    "        )\n",
    "        _log.debug(res.document._export_to_indented_text(max_text_len=16))\n",
    "\n",
    "        # Export Docling document format to markdown, JSON, and YAML in the respective folder\n",
    "        with (out_dir / f\"{res.input.file.stem}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(res.document.export_to_markdown())\n",
    "\n",
    "        with (out_dir / f\"{res.input.file.stem}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(json.dumps(res.document.export_to_dict(), indent=4))\n",
    "\n",
    "        with (out_dir / f\"{res.input.file.stem}.yaml\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(yaml.safe_dump(res.document.export_to_dict()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m doc_converter \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     12\u001b[0m     DocumentConverter(  \u001b[38;5;66;03m# all of the below is optional, has internal defaults.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         allowed_formats\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m conv_results \u001b[38;5;241m=\u001b[39m doc_converter\u001b[38;5;241m.\u001b[39mconvert_all(input_paths)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m conv_results:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Create an output directory for each input file\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     out_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m res\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mstem\n\u001b[0;32m     38\u001b[0m     out_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\document_converter.py:212\u001b[0m, in \u001b[0;36mDocumentConverter.convert_all\u001b[1;34m(self, source, headers, raises_on_error, max_num_pages, max_file_size)\u001b[0m\n\u001b[0;32m    209\u001b[0m conv_res_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert(conv_input, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error)\n\u001b[0;32m    211\u001b[0m had_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv_res \u001b[38;5;129;01min\u001b[39;00m conv_res_iter:\n\u001b[0;32m    213\u001b[0m     had_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error \u001b[38;5;129;01mand\u001b[39;00m conv_res\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    215\u001b[0m         ConversionStatus\u001b[38;5;241m.\u001b[39mSUCCESS,\n\u001b[0;32m    216\u001b[0m         ConversionStatus\u001b[38;5;241m.\u001b[39mPARTIAL_SUCCESS,\n\u001b[0;32m    217\u001b[0m     }:\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\document_converter.py:247\u001b[0m, in \u001b[0;36mDocumentConverter._convert\u001b[1;34m(self, conv_input, raises_on_error)\u001b[0m\n\u001b[0;32m    238\u001b[0m _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing to convert document batch...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m    248\u001b[0m     partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_document, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error),\n\u001b[0;32m    249\u001b[0m     input_batch,\n\u001b[0;32m    250\u001b[0m ):\n\u001b[0;32m    251\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    252\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\document_converter.py:288\u001b[0m, in \u001b[0;36mDocumentConverter._process_document\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m    284\u001b[0m valid \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_formats\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 288\u001b[0m     conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\document_converter.py:311\u001b[0m, in \u001b[0;36mDocumentConverter._execute_pipeline\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m    309\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipeline(in_doc\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     conv_res \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\pipeline\\base_pipeline.py:44\u001b[0m, in \u001b[0;36mBasePipeline.execute\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(\n\u001b[0;32m     40\u001b[0m         conv_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_total\u001b[39m\u001b[38;5;124m\"\u001b[39m, scope\u001b[38;5;241m=\u001b[39mProfilingScope\u001b[38;5;241m.\u001b[39mDOCUMENT\n\u001b[0;32m     41\u001b[0m     ):\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# These steps are building and assembling the structure of the\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# output DoclingDocument\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m         conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_document(conv_res)\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\pipeline\\base_pipeline.py:150\u001b[0m, in \u001b[0;36mPaginatedPipeline._build_document\u001b[1;34m(self, conv_res)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# 2. Run pipeline stages\u001b[39;00m\n\u001b[0;32m    148\u001b[0m pipeline_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_on_pages(conv_res, init_pages)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pipeline_pages:  \u001b[38;5;66;03m# Must exhaust!\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    153\u001b[0m end_batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\pipeline\\base_pipeline.py:116\u001b[0m, in \u001b[0;36mPaginatedPipeline._apply_on_pages\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_pipe:\n\u001b[0;32m    114\u001b[0m     page_batch \u001b[38;5;241m=\u001b[39m model(conv_res, page_batch)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\models\\page_assemble_model.py:60\u001b[0m, in \u001b[0;36mPageAssembleModel.__call__\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m, conv_res: ConversionResult, page_batch: Iterable[Page]\n\u001b[0;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Page]:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m page_batch:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mis_valid():\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\models\\table_structure_model.py:136\u001b[0m, in \u001b[0;36mTableStructureModel.__call__\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m page_batch:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mis_valid():\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling\\models\\layout_model.py:187\u001b[0m, in \u001b[0;36mLayoutModel.__call__\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m page\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m clusters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, pred_item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_predictor\u001b[38;5;241m.\u001b[39mpredict(page\u001b[38;5;241m.\u001b[39mget_image(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m))\n\u001b[0;32m    189\u001b[0m ):\n\u001b[0;32m    190\u001b[0m     label \u001b[38;5;241m=\u001b[39m DocItemLabel(\n\u001b[0;32m    191\u001b[0m         pred_item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m     )  \u001b[38;5;66;03m# Temporary, until docling-ibm-model uses docling-core types\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m Cluster(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mix,\n\u001b[0;32m    198\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m         cells\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\docling_ibm_models\\layoutmodel\\layout_predictor.py:143\u001b[0m, in \u001b[0;36mLayoutPredictor.predict\u001b[1;34m(self, orig_img)\u001b[0m\n\u001b[0;32m    137\u001b[0m resize \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_size}\n\u001b[0;32m    138\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_processor(\n\u001b[0;32m    139\u001b[0m     images\u001b[38;5;241m=\u001b[39mpage_img,\n\u001b[0;32m    140\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m     size\u001b[38;5;241m=\u001b[39mresize,\n\u001b[0;32m    142\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device)\n\u001b[1;32m--> 143\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m    144\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_processor\u001b[38;5;241m.\u001b[39mpost_process_object_detection(\n\u001b[0;32m    145\u001b[0m     outputs,\n\u001b[0;32m    146\u001b[0m     target_sizes\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([page_img\u001b[38;5;241m.\u001b[39msize[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]),\n\u001b[0;32m    147\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threshold,\n\u001b[0;32m    148\u001b[0m )\n\u001b[0;32m    150\u001b[0m w, h \u001b[38;5;241m=\u001b[39m page_img\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\transformers\\models\\rt_detr\\modeling_rt_detr.py:2094\u001b[0m, in \u001b[0;36mRTDetrForObjectDetection.forward\u001b[1;34m(self, pixel_values, pixel_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, **loss_kwargs)\u001b[0m\n\u001b[0;32m   2088\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2089\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m   2090\u001b[0m )\n\u001b[0;32m   2092\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 2094\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2106\u001b[0m denoising_meta_values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2107\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mdenoising_meta_values \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m )\n\u001b[0;32m   2110\u001b[0m outputs_class \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mintermediate_logits \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\transformers\\models\\rt_detr\\modeling_rt_detr.py:1811\u001b[0m, in \u001b[0;36mRTDetrModel.forward\u001b[1;34m(self, pixel_values, pixel_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1807\u001b[0m     pixel_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(((batch_size, height, width)), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1809\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(pixel_values, pixel_mask)\n\u001b[1;32m-> 1811\u001b[0m proj_feats \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_input_proj[level](source) \u001b[38;5;28;01mfor\u001b[39;00m level, (source, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features)]\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1815\u001b[0m         proj_feats,\n\u001b[0;32m   1816\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1817\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1818\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1819\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\transformers\\models\\rt_detr\\modeling_rt_detr.py:1811\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1807\u001b[0m     pixel_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(((batch_size, height, width)), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1809\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(pixel_values, pixel_mask)\n\u001b[1;32m-> 1811\u001b[0m proj_feats \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_input_proj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m level, (source, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features)]\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1815\u001b[0m         proj_feats,\n\u001b[0;32m   1816\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1817\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1818\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1819\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\livMatS\\.conda\\envs\\docling\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting pdf to md, json, and yaml formats + Exporting Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Define input paths and output directory\n",
    "    input_paths = [\n",
    "        Path(\"inputs/Improving_machine-learning_models.pdf\"),\n",
    "        # Path(\"inputs/tutorial_open-source_large_language_models.pdf\"),\n",
    "    ]\n",
    "    output_root_dir = Path(\"outputs\")\n",
    "\n",
    "    # Configure DocumentConverter\n",
    "    doc_converter = DocumentConverter(\n",
    "        allowed_formats=[\n",
    "            InputFormat.PDF,\n",
    "            InputFormat.IMAGE,\n",
    "            InputFormat.DOCX,\n",
    "            InputFormat.HTML,\n",
    "            InputFormat.PPTX,\n",
    "            InputFormat.ASCIIDOC,\n",
    "            InputFormat.MD,\n",
    "        ],\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(\n",
    "                pipeline_cls=StandardPdfPipeline, backend=PyPdfiumDocumentBackend\n",
    "            ),\n",
    "            InputFormat.DOCX: WordFormatOption(\n",
    "                pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for input_path in input_paths:\n",
    "        if not input_path.exists():\n",
    "            _log.warning(f\"Input file {input_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Convert document\n",
    "        conv_res = doc_converter.convert(input_path)\n",
    "\n",
    "        # Create output directory for this input\n",
    "        doc_filename = conv_res.input.file.stem\n",
    "        output_dir = output_root_dir / doc_filename\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save document outputs in various formats\n",
    "        with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(conv_res.document.export_to_markdown())\n",
    "\n",
    "        with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(json.dumps(conv_res.document.export_to_dict(), indent=4))\n",
    "\n",
    "        with (output_dir / f\"{doc_filename}.yaml\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(yaml.safe_dump(conv_res.document.export_to_dict()))\n",
    "\n",
    "        # Export tables if present\n",
    "        for table_ix, table in enumerate(conv_res.document.tables):\n",
    "            table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "            print(f\"## Table {table_ix}\")\n",
    "            print(table_df.to_markdown())\n",
    "\n",
    "            # Save the table as CSV\n",
    "            table_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n",
    "            _log.info(f\"Saving CSV table to {table_csv_filename}\")\n",
    "            table_df.to_csv(table_csv_filename)\n",
    "\n",
    "            # Save the table as HTML\n",
    "            table_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n",
    "            _log.info(f\"Saving HTML table to {table_html_filename}\")\n",
    "            with table_html_filename.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "                fp.write(table.export_to_html())\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    _log.info(f\"All documents converted and tables exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Improving_machine-learning_models.pdf\n",
      "INFO:docling.document_converter:Finished converting document Improving_machine-learning_models.pdf in 41.75 sec.\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-1.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-1.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-2.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-2.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-3.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-3.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-4.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-4.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-5.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-5.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-6.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-6.html\n",
      "INFO:__main__:Saving CSV table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-7.csv\n",
      "INFO:__main__:Saving HTML table to outputs\\Improving_machine-learning_models\\Improving_machine-learning_models-table-7.html\n",
      "INFO:__main__:All documents converted and tables exported in 42.93 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Table 0\n",
      "|    | Property    | Units                 | mean    |   std |    MAE |   err (%) |\n",
      "|---:|:------------|:----------------------|:--------|------:|-------:|----------:|\n",
      "|  0 | Gap         | eV                    | 0.17    |  0.65 | 0.054  |      33   |\n",
      "|  1 | Eform       | eVatom -  1           | -  0.48 |  0.96 | 0.06   |      13   |\n",
      "|  2 | Ehull       | eVatom -  1           | 0.30    |  0.48 | 0.058  |      19   |\n",
      "|  3 | E tot /atom | eVatom -  1           | -  5.2  |  1.9  | 0.063  |       1.2 |\n",
      "|  4 | Mag/vol     | B -  3              | 0.0083  |  0.02 | 0.0024 |      29   |\n",
      "|  5 | Vol/atom    | 3atom -  1           | 24      |  9.1  | 0.62   |       2.5 |\n",
      "|  6 | DOS/atom    | states (eV atom) -  1 | 0.79    |  0.63 | 0.12   |      15   |\n",
      "## Table 1\n",
      "|    | Property    | Units                 | mean    |   std |    MAE |   err (%) |\n",
      "|---:|:------------|:----------------------|:--------|------:|-------:|----------:|\n",
      "|  0 | Gap         | eV                    | 0.13    | 0.58  | 0.03   |     23    |\n",
      "|  1 | Eform       | eVatom -  1           | -  0.25 | 0.93  | 0.016  |      6.5  |\n",
      "|  2 | Ehull       | eVatom -  1           | 0.41    | 0.54  | 0.018  |      4.4  |\n",
      "|  3 | E tot /atom | eVatom -  1           | -  5.1  | 2     | 0.039  |      0.76 |\n",
      "|  4 | Mag/vol     | B -  3              | 0.0090  | 0.021 | 0.0027 |     30    |\n",
      "|  5 | Vol/atom    | 3 atom -  1          | 24      | 9.2   | 0.039  |      0.16 |\n",
      "|  6 | DOS/atom    | states (eV atom) -  1 | 0.81    | 0.62  | 0.14   |     17    |\n",
      "## Table 2\n",
      "|    |           |   Failed |   Outliers | MPE     |   MAPE |   MAE |\n",
      "|---:|:----------|---------:|-----------:|:--------|-------:|------:|\n",
      "|  0 | M3GNET 2D |   0.38   |       0.57 | 0.94    |    7.4 | 13    |\n",
      "|  1 | M3GNET    |   0.44   |       0.38 | 1.5     |    7.8 | 14    |\n",
      "|  2 | MACE 2D   |   0.33   |       0.21 | 0.018   |    5.9 | 10    |\n",
      "|  3 | MACE      |   0.37   |       0.34 | 2.1     |    7.8 | 14    |\n",
      "|  4 | M3GNET 2D |   1.1    |       1.1  | -  0.72 |    7.3 |  2.5  |\n",
      "|  5 | M3GNET    |   1      |       1.1  | -  1.3  |    6.9 |  2.4  |\n",
      "|  6 | MACE 2D   |   1      |       0.31 | -  0.81 |    5.5 |  1.8  |\n",
      "|  7 | MACE      |   1.4    |       0.58 | 0.46    |    6.2 |  2.1  |\n",
      "|  8 | M3GNET 2D |   0.098  |       0.24 | 1.6     |    7.6 |  2    |\n",
      "|  9 | M3GNET    |   0.0057 |       0.47 | -  1.3  |    4.6 |  1.2  |\n",
      "| 10 | MACE 2D   |   0.58   |       0.14 | 2.0     |    5.8 |  1.5  |\n",
      "| 11 | MACE      |   0.12   |       0.13 | -  0.40 |    3.5 |  0.89 |\n",
      "## Table 3\n",
      "|    |    |           |   Failed |   Outliers | MPE     |   MAPE |   MAE |\n",
      "|---:|:---|:----------|---------:|-----------:|:--------|-------:|------:|\n",
      "|  0 | 1D | M3GNET 2D |   0.38   |      0.053 | 0.10    |    3.4 | 0.13  |\n",
      "|  1 |    | M3GNET    |   0.44   |      0.12  | 0.27    |    7.2 | 0.28  |\n",
      "|  2 |    | MACE 2D   |   0.33   |      0.045 | 0.042   |    1.8 | 0.075 |\n",
      "|  3 |    | MACE      |   0.37   |      0.083 | 0.058   |    3.1 | 0.13  |\n",
      "|  4 | 2D | M3GNET 2D |   1.1    |      2.8   | 0.056   |    3.2 | 0.12  |\n",
      "|  5 |    | M3GNET    |   1      |      0.056 | 0.20    |    5.4 | 0.2   |\n",
      "|  6 |    | MACE 2D   |   1      |      0.036 | 0.025   |    1.2 | 0.045 |\n",
      "|  7 |    | MACE      |   1.4    |      0.042 | 0.064   |    2.3 | 0.088 |\n",
      "|  8 | 3D | M3GNET 2D |   0.098  |     16     | -  0.10 |    6.5 | 0.29  |\n",
      "|  9 |    | M3GNET    |   0.0057 |      0.1   | 0.10    |    2.8 | 0.12  |\n",
      "| 10 |    | MACE 2D   |   0.58   |      0.16  | 0.036   |    2.7 | 0.12  |\n",
      "| 11 |    | MACE      |   0.12   |      0.035 | 0.048   |    1.7 | 0.078 |\n",
      "## Table 4\n",
      "|    | Model   |   MAD |   MAE | Time (s)   |\n",
      "|---:|:--------|------:|------:|:-----------|\n",
      "|  0 | M3GNET  | 0.038 | 0.06  | 1.96       |\n",
      "|  1 | MACE    | 0.022 | 0.039 | 12.1 (1.4) |\n",
      "|  2 | CGAT    | 0.023 | 0.06  | 0.002      |\n",
      "## Table 5\n",
      "|    | Metric                          |   M3GNET PBESOL |   MACE PBESOL |\n",
      "|---:|:--------------------------------|----------------:|--------------:|\n",
      "|  0 | Failed percentage (%)           |           0.096 |         0.25  |\n",
      "|  1 | MAE (eVatom -  1 )              |           0.057 |         0.044 |\n",
      "|  2 | RMSE (eVatom -  1 )             |           0.086 |         0.083 |\n",
      "|  3 | Number of outliers              |           3     |         2     |\n",
      "|  4 | RMSE w.o. (eVatom -  1 )        |           0.082 |         0.072 |\n",
      "|  5 | 90th quantile AE (eVatom -  1 ) |           0.122 |         0.09  |\n",
      "|  6 | MAD (eVatom -  1 )              |           0.042 |         0.029 |\n",
      "|  7 | MAE Volume ( 3 atom -  1 )     |           0.5   |         0.86  |\n",
      "## Table 6\n",
      "|    | 0          | 1                                                                                                                                                                                                                                                                                                                                         |\n",
      "|---:|:-----------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | [36]       | J. Schmidt, L. Chen, S. Botti, M.A.L. Marques, Predicting the stability of ternary intermetallics with density functional theory and machine learning, J. Chem. Phys.                                                                                                                                                                     |\n",
      "|  1 |            | 148 (2018): 241728 .                                                                                                                                                                                                                                                                                                                      |\n",
      "|  2 | [37]       | H.-C. Wang, S. Botti, M.A.L. Marques, Predicting stable crystalline compounds                                                                                                                                                                                                                                                             |\n",
      "|  3 | [38]       | using chemical similarity, npj Comput. Mater. 7 (2021) 12 . H.-C. Wang, J. Schmidt, S. Botti, M.A.L. Marques, A high-throughput study of oxynitride, oxyfluoride and nitrofluoride perovskites, J. Mater. Chem. A 9 (2021) 8501 - 8513 .                                                                                                  |\n",
      "|  4 | [39]       | H.-C. Wang, J. Schmidt, M.A.L. Marques, L. Wirtz, A.H. Romero, Symmetry-based computational search for novel binary and ternary 2d materials, 2D Mater. 10 (2023): 035007 .                                                                                                                                                               |\n",
      "|  5 | [40]       | J.P. Perdew, K. Burke, M. Ernzerhof, Generalized gradient approximation made simple, Phys. Rev. Lett. 77 (1996) 3865 - 3868 .                                                                                                                                                                                                             |\n",
      "|  6 | [41]       | J.P. Perdew, A. Ruzsinszky, G.I. Csonka, O.A. Vydrov, G.E. Scuseria, L. A. Constantin, X. Zhou, K. Burke, Restoring the density-gradient expansion for                                                                                                                                                                                    |\n",
      "|  7 | [42]       | exchange in solids and surfaces, Phys. Rev. Lett. 100 (2008): 136406 . J. Sun, A. Ruzsinszky, J.P. Perdew, Strongly constrained and appropriately normed semilocal density functional, Phys. Rev. Lett. 115 (2015): 036402 .                                                                                                              |\n",
      "|  8 |            | [43] Y. Zhang, D.A. Kitchaev, J. Yang, T. Chen, S.T. Dacek, R.A. Sarmiento-P ' erez, M.A. L. Marques, H. Peng, G. Ceder, J.P. Perdew, J. Sun, Efficient first-principles prediction of solid stability: towards chemical accuracy, npj Comput. Mater. 4                                                                                   |\n",
      "|  9 | [44]       | R. Sarmiento-P ' erez, S. Botti, M.A.L. Marques, Optimized exchange and correlation semilocal functional for the calculation of energies of formation, J. Chem. Theor. Comput. 11 (2015) 3844 - 3850 .                                                                                                                                    |\n",
      "| 10 | [45]       | F. Tran, J. Stelzl, P. Blaha, Rungs 1 to 4 of dft jacob ' s ladder: extensive test on the lattice constant, bulk modulus, and cohesive energy of solids, J. Chem. Phys. 144 (2016): 204120 .                                                                                                                                              |\n",
      "| 11 | [46]  [47] | P. Borlido, T. Aull, A.W. Huran, F. Tran, M.A.L. Marques, S. Botti, Large-scale benchmark of exchange - correlation functionals for the determination of electronic band gaps of solids, J. Chem. Theor. Comput. 15 (2019) 5069 - 5079 . J.W. Furness, A.D. Kaplan, J. Ning, J.P. Perdew, J. Sun, Accurate and numerically                |\n",
      "| 12 | [48]       | efficient r2scan meta-generalized gradient approximation, J. Phys. Chem. Lett. 11 (2020) 8208 - 8215 . R. Kingsbury, A.S. Gupta, C.J. Bartel, J.M. Munro, S. Dwaraknath, M. Horton, K. A. Persson, Performance comparison of r 2 SCAN and scan metagga density                                                                            |\n",
      "| 13 |            | functionals for solid materials via an automated, high-throughput computational workflow, Phys. Rev. Mater. 6 (2022): 013801 .                                                                                                                                                                                                            |\n",
      "| 14 | [49]       | L. Monacelli, R. Bianco, M. Cherubini, M. Calandra, I. Errea, F. Mauri, The stochastic self-consistent harmonic approximation: calculating vibrational properties of materials with full quantum and anharmonic effects, J. Phys. Condens. Matter 33 (2021): 363001 .                                                                     |\n",
      "| 15 | [50]       | C. Sutton, S.V. Levchenko, First-principles atomistic thermodynamics and configurational entropy, Front. Chem. 8 (2020), https://doi.org/10.3389/ fchem.2020.00757 .                                                                                                                                                                      |\n",
      "| 16 | [51]       | J. Leeman, Y. Liu, J. Stiles, S.B. Lee, P. Bhatt, L.M. Schoop, R.G. Palgrave, Challenges in high-throughput inorganic materials prediction and autonomous synthesis, PRX Energy 3 (2024): 011002 .                                                                                                                                        |\n",
      "| 17 |            | [52] A.K. Cheetham, R. Seshadri, Artificial intelligence driving materials discovery? perspective on the article: scaling deep learning for materials discovery, Chem. Mater. 36 (2024) 3490 . [53] A. Merchant, S. Batzner, S.S. Schoenholz, M. Aykol, G. Cheon, E.D. Cubuk, Scaling                                                     |\n",
      "| 18 | [54]       | deep learning for materials discovery, Nature 624 (2023) 80 - 85 . C. Chen, S.P. Ong, A universal graph deep learning interatomic potential for the periodic table, Nat. Comput. Sci. 2 (2022) 718 - 728 .                                                                                                                                |\n",
      "| 19 | [55]       | I. Batatia, D.P. Kovacs, G.N.C. Simm, C. Ortner, G. Csanyi, MACE: higher order equivariant message passing neural networks for fast and accurate force fields, in: A.H. Oh, A. Agarwal, D. Belgrave, K. Cho (Eds.), Adv. Neural Inf. Process. Syst., 2022 .                                                                               |\n",
      "| 20 | [56]       | C. Zeni, R. Pinsler, D. Zgner, A. Fowler, M. Horton, X. Fu, S. Shysheya, J. Crabb ' e, L. Sun, J. Smith, B. Nguyen, H. Schulz, S. Lewis, C.-W. Huang, Z. Lu, Y. Zhou, H. Yang, H. Hao, J. Li, R. Tomioka, T. Xie, Mattergen: a Generative Model for Inorganic Materials Design, 2023 arXiv:2312.03687 .                                  |\n",
      "| 21 | [57]       | S. Das, A. Sebastian, E. Pop, C.J. McClellan, A.D. Franklin, T. Grasser, T. Knobloch, Y. Illarionov, A.V. Penumatcha, J. Appenzeller, Z. Chen, W. Zhu, I. Asselberghs, L.- J. Li, U.E. Avci, N. Bhat, T.D. Anthopoulos, R. Singh, Transistors based on two  dimensional materials for future integrated circuits, Nat. Electron. 4 (2021) |\n",
      "| 22 |            | [58] A. Avsar, H. Ochoa, F. Guinea, B. Ozyilmaz,  B.J. van Wees, I.J. Vera-Marun, Colloquium: spintronics in graphene and other two-dimensional materials, Rev. Mod. Phys. 92 (2020): 021003 .                                                                                                                                            |\n",
      "| 23 |            | dimensional materials, Nano-Micro Lett. 12 (2020) 1 . [60] A. Bordoloi, A.C. Garcia-Castro, Z. Romestan, A.H. Romero, S. Singh, Promises and Technological Prospects of Two-Dimensional Rashba Materials, 2024 arXiv: 2404.15071 .                                                                                                        |\n",
      "| 24 | [61]       | K. Khan, A.K. Tareen, M. Aslam, R. Wang, Y. Zhang, A. Mahmood, Z. Ouyang, H. Zhang, Z. Guo, Recent developments in emerging two-dimensional materials and their applications, J. Mater. Chem. C 8 (2020) 387 .                                                                                                                            |\n",
      "| 25 | [62]       | C. Chang, W. Chen, Y. Chen, Y. Chen, Y. Chen, F. Ding, C. Fan, H. Jin Fan, Z. Fan, C. Gong, Y. Gong, Q. He, X. Hong, S. Hu, W. Hu, W. Huang, Y. Huang, W. Ji, D. Li,                                                                                                                                                                      |\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting pdf to md, json, and yaml formats + Exporting Tables + Image export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RESOLUTION_SCALE = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Define input paths and output root directory\n",
    "    input_paths = [\n",
    "        # Path(\"inputs/Improving_machine-learning_models.pdf\"),\n",
    "        # Path(\"inputs/tutorial_open-source_large_language_models.pdf\"),\n",
    "        Path(\"inputs/Finite_Element_Modeling_Shape_Changes_Plant_Cells.pdf\"),\n",
    "    ]\n",
    "    output_root_dir = Path(\"outputs\")\n",
    "\n",
    "    accelerator_options = AcceleratorOptions(\n",
    "        num_threads=8, device=AcceleratorDevice.CPU\n",
    "    )\n",
    "\n",
    "    # Configure PDF pipeline options\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.do_picture_description = True\n",
    "    pipeline_options.picture_description_options = smolvlm_picture_description\n",
    "\n",
    "    pipeline_options.picture_description_options.prompt = (\n",
    "        \"Describe the image in three sentences. Be consise and accurate.\"\n",
    "    )\n",
    "\n",
    "    pipeline_options.accelerator_options = accelerator_options\n",
    "    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "    pipeline_options.generate_page_images = True\n",
    "    pipeline_options.generate_picture_images = True\n",
    "    pipeline_options.do_ocr = True\n",
    "    pipeline_options.do_table_structure = True\n",
    "    pipeline_options.table_structure_options.do_cell_matching = True\n",
    "    ocr_options = TesseractCliOcrOptions(force_full_page_ocr=True)\n",
    "    # ocr_options = EasyOcrOptions(force_full_page_ocr=True)\n",
    "    pipeline_options.ocr_options = ocr_options\n",
    "\n",
    "    # Configure DocumentConverter\n",
    "    doc_converter = DocumentConverter(\n",
    "        allowed_formats=[\n",
    "            InputFormat.PDF,\n",
    "            InputFormat.IMAGE,\n",
    "            InputFormat.DOCX,\n",
    "            InputFormat.HTML,\n",
    "            InputFormat.PPTX,\n",
    "            InputFormat.ASCIIDOC,\n",
    "            InputFormat.MD,\n",
    "        ],\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(\n",
    "                pipeline_cls=StandardPdfPipeline,\n",
    "                backend=PyPdfiumDocumentBackend,\n",
    "                pipeline_options=pipeline_options,\n",
    "            ),\n",
    "            InputFormat.DOCX: WordFormatOption(pipeline_cls=SimplePipeline),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # result = doc_converter.convert(input_paths)\n",
    "    # result = doc_converter.convert([str(path) for path in input_paths])\n",
    "    for input_path in input_paths:\n",
    "        result = doc_converter.convert(str(input_path))\n",
    "\n",
    "    for input_path in input_paths:\n",
    "        if not input_path.exists():\n",
    "            _log.warning(f\"Input file {input_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Convert document\n",
    "        conv_res = doc_converter.convert(input_path)\n",
    "\n",
    "        # Create output directory for this input\n",
    "        doc_filename = conv_res.input.file.stem\n",
    "        output_dir = output_root_dir / doc_filename\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save page images\n",
    "        for page_no, page in conv_res.document.pages.items():\n",
    "            page_image_filename = output_dir / f\"{doc_filename}-page-{page_no}.png\"\n",
    "            with page_image_filename.open(\"wb\") as fp:\n",
    "                page.image.pil_image.save(fp, format=\"PNG\")\n",
    "\n",
    "        # Save images of figures and tables\n",
    "        table_counter = 0\n",
    "        picture_counter = 0\n",
    "        for element, _level in conv_res.document.iterate_items():\n",
    "            if isinstance(element, TableItem):\n",
    "                table_counter += 1\n",
    "                table_image_filename = (\n",
    "                    output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
    "                )\n",
    "                with table_image_filename.open(\"wb\") as fp:\n",
    "                    element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "            if isinstance(element, PictureItem):\n",
    "                picture_counter += 1\n",
    "                picture_image_filename = (\n",
    "                    output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                f\"Picture {element.self_ref}\\n\"\n",
    "                f\"Caption: {element.caption_text(doc=result.document)}\\n\"\n",
    "                f\"Annotations: {element.annotations}\"\n",
    "                )\n",
    "\n",
    "                with picture_image_filename.open(\"wb\") as fp:\n",
    "                    element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "        # Save markdown with embedded pictures\n",
    "        md_embedded_filename = output_dir / f\"{doc_filename}-with-images.md\"\n",
    "        conv_res.document.save_as_markdown(md_embedded_filename, image_mode=ImageRefMode.EMBEDDED)\n",
    "\n",
    "        # Save markdown with externally referenced pictures\n",
    "        md_referenced_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "        conv_res.document.save_as_markdown(md_referenced_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "        # Save HTML with externally referenced pictures\n",
    "        html_referenced_filename = output_dir / f\"{doc_filename}-with-image-refs.html\"\n",
    "        conv_res.document.save_as_html(html_referenced_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "        # Save document outputs in various formats\n",
    "        with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(conv_res.document.export_to_markdown())\n",
    "\n",
    "        with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(conv_res.document.export_to_text())\n",
    "\n",
    "        with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(json.dumps(conv_res.document.export_to_dict(), indent=4))\n",
    "\n",
    "        with (output_dir / f\"{doc_filename}.yaml\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "            fp.write(yaml.safe_dump(conv_res.document.export_to_dict()))\n",
    "\n",
    "        # Export tables if present\n",
    "        for table_ix, table in enumerate(conv_res.document.tables):\n",
    "            table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "            print(f\"## Table {table_ix}\")\n",
    "            print(table_df.to_markdown())\n",
    "\n",
    "            # Save the table as CSV\n",
    "            table_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n",
    "            _log.info(f\"Saving CSV table to {table_csv_filename}\")\n",
    "            table_df.to_csv(table_csv_filename)\n",
    "\n",
    "            # Save the table as HTML\n",
    "            table_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n",
    "            _log.info(f\"Saving HTML table to {table_html_filename}\")\n",
    "            with table_html_filename.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "                fp.write(table.export_to_html())\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    _log.info(f\"All documents converted, images, and tables exported in {end_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for DocumentConverter.convert\n1.lax-or-strict[lax=union[json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]],function-after[path_validator(), str]],strict=json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]]]\n  Input should be an instance of Path [type=is_instance_of, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of\n1.str\n  Input should be a valid string [type=string_type, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n1.DocumentStream\n  Input should be a valid dictionary or instance of DocumentStream [type=model_type, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 60\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# result = doc_converter.convert(input_paths)\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdoc_converter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_paths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_path \u001b[38;5;129;01min\u001b[39;00m input_paths:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_path\u001b[38;5;241m.\u001b[39mexists():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_validate_call.py:38\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\_internal\\_validate_call.py:111\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 111\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for DocumentConverter.convert\n1.lax-or-strict[lax=union[json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]],function-after[path_validator(), str]],strict=json-or-python[json=function-after[path_validator(), str],python=is-instance[Path]]]\n  Input should be an instance of Path [type=is_instance_of, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of\n1.str\n  Input should be a valid string [type=string_type, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type\n1.DocumentStream\n  Input should be a valid dictionary or instance of DocumentStream [type=model_type, input_value=['inputs\\\\Finite_Element_...hanges_Plant_Cells.pdf'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/model_type"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docling version: 2.23.0\n",
      "Docling Core version: 2.19.1\n",
      "Docling IBM Models version: 3.3.2\n",
      "Docling Parse version: 3.3.1\n",
      "Python: cpython-312 (3.12.9)\n",
      "Platform: Windows-11-10.0.26100-SP0\n"
     ]
    }
   ],
   "source": [
    "!docling --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docling_python_3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
